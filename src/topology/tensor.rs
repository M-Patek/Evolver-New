// COPYRIGHT (C) 2025 M-Patek. ALL RIGHTS RESERVED.

use serde::{Serialize, Deserialize};
use crate::core::affine::AffineTuple;
use crate::core::algebra::Vector;
use crate::topology::folding::HyperFolder;
use crate::topology::merkle::CausalTrace;

/// ğŸ§  HyperTensor: å…¨æ¯é€»è¾‘å¼ é‡
///
/// è¿™æ˜¯ç½‘ç»œå¯¹ä¸€æ®µè¾“å…¥åºåˆ— (Context Window) çš„æœ€ç»ˆç†è§£ã€‚
/// å®ƒæ—¢åŒ…å«ç»“æœ (Root)ï¼Œä¹ŸåŒ…å«è¿‡ç¨‹ (Trace)ã€‚
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct HyperTensor {
    /// ğŸ“ Global Root: æœ€ç»ˆæŠ˜å å‡ºçš„é€»è¾‘çŠ¶æ€
    /// ä»£è¡¨äº†æ•´æ®µè¾“å…¥çš„ "è¯­ä¹‰æ€»å’Œ"ã€‚
    pub root: AffineTuple,

    /// ğŸï¸ Causal Trace: æ¢¯åº¦ç£å¸¦ (Optional)
    /// ä»…åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ç”Ÿæˆã€‚è®°å½•äº†ä» Leaf åˆ° Root çš„æ‰€æœ‰è®¡ç®—æ­¥éª¤ï¼Œ
    /// ç”¨äºåå‘ä¼ æ’­ (Backpropagation) æˆ–ä»£æ•°é€†è§£ã€‚
    pub trace: Option<CausalTrace>,
}

impl HyperTensor {
    /// ğŸ†• Genesis: åˆ›å»ºä¸€ä¸ªç©ºçš„ HyperTensor
    pub fn identity() -> Self {
        HyperTensor {
            root: AffineTuple::identity(),
            trace: None,
        }
    }

    /// ğŸš€ Forward Pass (æ„é€ å‡½æ•°)
    ///
    /// å°†ä¸€ä¸²åŸå§‹çš„ Token Embeddings è½¬æ¢ä¸ºå…¨æ¯å¼ é‡ã€‚
    ///
    /// * `inputs`: è¾“å…¥çš„ä»¿å°„å…ƒç»„åºåˆ— (Leaf Nodes)ã€‚
    /// * `training_mode`: 
    ///     - `true`: å¼€å¯æ¢¯åº¦è¿½è¸ª (æ…¢é€Ÿï¼Œç”Ÿæˆ Trace)ã€‚
    ///     - `false`: å¼€å¯å¹¶è¡ŒæŠ˜å  (æé€Ÿï¼Œæ—  Trace)ã€‚
    pub fn forward(inputs: &[AffineTuple], training_mode: bool) -> Self {
        if inputs.is_empty() {
            return Self::identity();
        }

        if training_mode {
            Self::fold_with_trace(inputs)
        } else {
            Self::fold_fast(inputs)
        }
    }

    /// ğŸï¸ Fast Folding (Inference Mode)
    /// åˆ©ç”¨ Rayon è¿›è¡Œå¹¶è¡Œè§„çº¦ï¼Œé€Ÿåº¦æå¿«ï¼Œä½†ä¸ä¿ç•™æ¢¯åº¦å›¾ã€‚
    fn fold_fast(inputs: &[AffineTuple]) -> Self {
        // è°ƒç”¨æˆ‘ä»¬ä¹‹å‰åœ¨ folding.rs å†™çš„å¹¶è¡Œç®—æ³•
        let root = HyperFolder::fold_timeline(inputs)
            .unwrap_or_else(AffineTuple::identity);

        HyperTensor {
            root,
            trace: None, // æ¨ç†æ¨¡å¼ä¸éœ€è¦æ¢¯åº¦
        }
    }

    /// ğŸ¢ Trace Folding (Training Mode)
    /// ä¸²è¡Œæ‰§è¡ŒæŠ˜å  (æˆ–åˆ†å±‚æŠ˜å )ï¼Œå¹¶ meticulously è®°å½•æ¯ä¸€æ­¥åˆ° CausalTraceã€‚
    /// è¿™æ ·æˆ‘ä»¬æ‰èƒ½æ‰§è¡Œ backward()ã€‚
    fn fold_with_trace(inputs: &[AffineTuple]) -> Self {
        let mut trace = CausalTrace::new();
        
        // 1. Register Leaf Nodes
        // å°†æ‰€æœ‰è¾“å…¥æ³¨å†Œåˆ° Trace ä¸­ï¼Œè·å–å®ƒä»¬çš„ Node ID
        let mut current_layer_ids: Vec<usize> = inputs.iter()
            .map(|leaf| trace.push_leaf(leaf.clone()))
            .collect();
        
        let mut current_layer_values = inputs.to_vec();

        // 2. Hierarchical Reduction (Tree Structure)
        // æ¨¡æ‹Ÿ Rayon çš„å½’çº¦è¿‡ç¨‹ï¼Œä½†æ˜¯æ˜¯è®°å½•åœ¨æ¡ˆçš„ã€‚
        // Loop until only one node remains (The Root).
        while current_layer_ids.len() > 1 {
            let mut next_layer_ids = Vec::new();
            let mut next_layer_values = Vec::new();

            // Pairwise folding (A+B, C+D, ...)
            for chunk_ids in current_layer_ids.chunks(2) {
                if chunk_ids.len() == 2 {
                    let left_id = chunk_ids[0];
                    let right_id = chunk_ids[1];
                    
                    // Retrieve values from the 'nodes' in trace (or logical cache)
                    // Note: In a real implementation we might cache values separately to avoid borrowing trace.
                    // Here we assume sequential processing matches indices.
                    // We need to fetch the actual AffineTuples computed previously.
                    // For simplicity, we carry `current_layer_values` alongside.
                    let val_idx = chunk_ids[0] % 2; // Logic simplification for demo loop matching
                    // Correct approach: track indices in `current_layer_values`
                    
                    // Let's refine the index logic:
                    // Since we are iterating chunks, we need corresponding values.
                    // But `chunks` on slice is hard with index mapping.
                    // Let's iterate by index steps.
                }
            }
            
            // Re-implementing simplified loop
            let mut i = 0;
            while i < current_layer_ids.len() {
                if i + 1 < current_layer_ids.len() {
                    let prev_id = current_layer_ids[i];
                    let next_id = current_layer_ids[i+1];
                    
                    let prev_val = &current_layer_values[i];
                    let next_val = &current_layer_values[i+1];

                    // Execute Logic: Next * Prev (Time Compose)
                    // or Merge (Space Fold) depending on context.
                    // Assume Time Folding for sequence tensor:
                    let result = next_val.compose(prev_val).expect("Fold Error");
                    
                    // Record in Tape
                    let new_id = trace.push_compose(prev_id, next_id, result.clone());
                    
                    next_layer_ids.push(new_id);
                    next_layer_values.push(result);
                    
                    i += 2;
                } else {
                    // Odd element out, carry over
                    next_layer_ids.push(current_layer_ids[i]);
                    next_layer_values.push(current_layer_values[i].clone());
                    i += 1;
                }
            }

            current_layer_ids = next_layer_ids;
            current_layer_values = next_layer_values;
        }

        HyperTensor {
            root: current_layer_values[0].clone(),
            trace: Some(trace),
        }
    }
    
    /// ğŸ” Introspection (è‡ªçœ)
    /// æ‰“å°é€»è¾‘æŠ˜å çš„æ·±åº¦å’Œå¤æ‚åº¦ã€‚
    pub fn complexity(&self) -> usize {
        match &self.trace {
            Some(t) => t.nodes.len(),
            None => 0, // å¿«é€Ÿæ¨¡å¼ä¸‹ä¸å¯çŸ¥
        }
    }
}
