// COPYRIGHT (C) 2025 M-Patek. ALL RIGHTS RESERVED.

use crate::core::algebra::{Matrix, Vector};
use crate::core::affine::AffineTuple;
use serde::{Serialize, Deserialize};

// âš ï¸ [REFACTOR NOTICE]:
// åŸ Merkle Tree æ¨¡å—å·²è¢«é‡æ„ä¸º "Gradient Tape" (æ¢¯åº¦ç£å¸¦)ã€‚
// å®ƒä¸å†è®¡ç®—å“ˆå¸Œï¼Œè€Œæ˜¯è®°å½•å¼ é‡è¿ç®—çš„æ‹“æ‰‘ç»“æ„ï¼Œç”¨äºåå‘ä¼ æ’­ã€‚

/// ğŸ“¼ OpType: è¿ç®—ç±»å‹
#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum OpType {
    TimeCompose,   // âŠ• (A * B)
    SpaceMerge,    // âŠ— (A + B) / 2
    LeafEmbedding, // Input -> Embedding
}

/// ğŸ“ TraceNode: è®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct TraceNode {
    pub id: usize,
    pub op: OpType,
    pub parents: Vec<usize>, // ä¸Šæ¸¸èŠ‚ç‚¹ ID (ä¾èµ–é¡¹)
    
    // ç¼“å­˜çš„å‰å‘ä¼ æ’­å€¼ (Forward Value)ï¼Œç”¨äºè®¡ç®—å±€éƒ¨æ¢¯åº¦
    // åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿™å¯èƒ½éœ€è¦ä»å†…å­˜ä¸­å¸è½½ (Checkpointing) ä»¥èŠ‚çœæ˜¾å­˜
    pub value: AffineTuple, 
}

/// ğŸï¸ CausalTrace: å› æœè¿½è¸ªå™¨ (The Gradient Tape)
///
/// è®°å½•äº†ä»è¾“å…¥ Token åˆ°æœ€ç»ˆç»“è®ºçš„æ‰€æœ‰å˜æ¢æ­¥éª¤ã€‚
/// è¿™æ˜¯ä¸€ä¸ªæœ‰å‘æ— ç¯å›¾ (DAG)ã€‚
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct CausalTrace {
    pub nodes: Vec<TraceNode>,
    pub active_path: Vec<usize>, // åªæœ‰å‚ä¸äº†æœ€ç»ˆè¾“å‡ºçš„èŠ‚ç‚¹æ‰ä¼šè¢«æ¿€æ´»
}

impl CausalTrace {
    pub fn new() -> Self {
        CausalTrace {
            nodes: Vec::new(),
            active_path: Vec::new(),
        }
    }

    /// è®°å½•ä¸€ä¸ªå¶å­èŠ‚ç‚¹
    pub fn push_leaf(&mut self, value: AffineTuple) -> usize {
        let id = self.nodes.len();
        self.nodes.push(TraceNode {
            id,
            op: OpType::LeafEmbedding,
            parents: vec![],
            value,
        });
        id
    }

    /// è®°å½•ä¸€ä¸ªæ—¶é—´æ¼”åŒ–æ“ä½œ (Compose)
    /// Parent A (Prev) -> Parent B (Next) -> Output
    pub fn push_compose(&mut self, prev_id: usize, next_id: usize, result: AffineTuple) -> usize {
        let id = self.nodes.len();
        self.nodes.push(TraceNode {
            id,
            op: OpType::TimeCompose,
            parents: vec![prev_id, next_id], // æ³¨æ„é¡ºåº: [Prev, Next]
            value: result,
        });
        id
    }

    /// è®°å½•ä¸€ä¸ªç©ºé—´æŠ˜å æ“ä½œ (Merge)
    pub fn push_merge(&mut self, left_id: usize, right_id: usize, result: AffineTuple) -> usize {
        let id = self.nodes.len();
        self.nodes.push(TraceNode {
            id,
            op: OpType::SpaceMerge,
            parents: vec![left_id, right_id],
            value: result,
        });
        id
    }

    /// ğŸ“‰ Auto-Differentiation Engine (è‡ªåŠ¨å¾®åˆ†å¼•æ“)
    ///
    /// ç»™å®šæœ€ç»ˆè¾“å‡ºçš„æ¢¯åº¦ dL/dOutputï¼Œåå‘è®¡ç®—æ‰€æœ‰ä¸­é—´èŠ‚ç‚¹çš„æ¢¯åº¦ã€‚
    /// è¿™é‡Œçš„å®ç°æ˜¯ç®€åŒ–çš„ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨ç™½ç›’æ¶æ„ä¸­æ‰‹åŠ¨å®ç° Backpropã€‚
    pub fn backward(&self, grad_output: &AffineTuple) -> Vec<AffineTuple> {
        let mut grads = vec![AffineTuple::identity(); self.nodes.len()];
        
        // åˆå§‹åŒ–æœ«ç«¯æ¢¯åº¦
        if let Some(last_node) = self.nodes.last() {
            grads[last_node.id] = grad_output.clone();
        }

        // åå‘éå† (Reverse Topological Order)
        for node in self.nodes.iter().rev() {
            let current_grad = &grads[node.id];

            match node.op {
                OpType::LeafEmbedding => {
                    // å¶å­èŠ‚ç‚¹ï¼Œæ¢¯åº¦åœæ­¢æµåŠ¨ (æˆ–è€…ä¼ ç»™ Embedding Layer)
                },
                OpType::TimeCompose => {
                    // Compose: Out = Next * Prev
                    // Inputs: parents[0] (Prev), parents[1] (Next)
                    let prev_idx = node.parents[0];
                    let next_idx = node.parents[1];
                    let prev_val = &self.nodes[prev_idx].value;
                    let next_val = &self.nodes[next_idx].value;

                    // Chain Rule for Non-Commutative Product:
                    // dL/dPrev = Next^T * dL/dOut
                    // dL/dNext = dL/dOut * Prev^T
                    
                    // 1. Gradient w.r.t Prev
                    // (Simplification: dealing with Linear part only for demo)
                    // In rigorous math: new_linear = next.linear * prev.linear
                    // grad_prev_linear = next.linear.T * grad_linear
                    // ... (Complete Jacobian implementation omitted for brevity)
                },
                OpType::SpaceMerge => {
                    // Merge: Out = (Left + Right) / 2
                    // Inputs: parents[0] (Left), parents[1] (Right)
                    // Gradients distribute evenly: dL/dLeft = 0.5 * dL/dOut
                    let left_idx = node.parents[0];
                    let right_idx = node.parents[1];
                    
                    let half_grad_linear = current_grad.linear.scale(0.5);
                    let half_grad_trans = current_grad.translation.scale(0.5);
                    let grad_down = AffineTuple::new(half_grad_linear, half_grad_trans);

                    // Accumulate gradients (in case a node splits into multiple paths)
                    // (Here we simplify assuming tree structure)
                }
            }
        }
        
        grads
    }
}
