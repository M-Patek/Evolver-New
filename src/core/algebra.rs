// COPYRIGHT (C) 2025 M-Patek. ALL RIGHTS RESERVED.

use serde::{Serialize, Deserialize};

// ==================================================================
// 1. åŸºç¡€ç±»å‹å®šä¹‰ (The Manifold Substrate)
// ==================================================================

/// ğŸ¯ Precision Selection
/// - Training: f32 (Standard Backpropagation)
/// - High-Fidelity Logic: f64
/// åœ¨ White-Box Evolver ä¸­ï¼Œé»˜è®¤ä½¿ç”¨ f32 ä»¥é€‚é… GPU å¼ é‡æ ¸å¿ƒã€‚
pub type Float = f32;

/// ğŸ“ Manifold Dimension (D)
/// é€»è¾‘æµå½¢çš„ç»´åº¦ã€‚å¿…é¡»ä¸ SPECIFICATION.md ä¸­çš„å®šä¹‰ä¸€è‡´ã€‚
/// ä¸ºäº†ç®€åŒ–æ¼”ç¤ºï¼Œè¿™é‡Œç¡¬ç¼–ç ä¸º 512ï¼Œå®é™…å·¥ç¨‹ä¸­å¯èƒ½æ˜¯æ³›å‹æˆ–é…ç½®é¡¹ã€‚
pub const MANIFOLD_DIM: usize = 512;

/// ğŸ›ï¸ Vector: é€»è¾‘æµå½¢ä¸Šçš„ç‚¹æˆ–ä½ç§»å‘é‡
/// Represents a point $v \in \mathbb{R}^D$
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct Vector {
    pub data: Vec<Float>,
}

/// ğŸ›ï¸ Matrix: çº¿æ€§å˜æ¢ç®—å­
/// Represents a linear map $W: \mathbb{R}^D \to \mathbb{R}^D$
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct Matrix {
    pub rows: usize,
    pub cols: usize,
    pub data: Vec<Float>,
}

// ==================================================================
// 2. çº¿æ€§ä»£æ•°æ ¸å¿ƒå®ç° (Linear Algebra Kernel)
// ==================================================================

impl Vector {
    /// åˆ›å»ºæ–°å‘é‡ (éœ€è¦æ£€æŸ¥ç»´åº¦)
    pub fn new(data: Vec<Float>) -> Self {
        if data.len() != MANIFOLD_DIM {
            // åœ¨ä¸¥æ ¼æ¨¡å¼ä¸‹åº”è¯¥ panic æˆ–è¿”å› Resultï¼Œè¿™é‡Œä¸ºäº†ç®€æ´ä¿æŒ lenient
            eprintln!("âš ï¸ Warning: Vector dimension mismatch. Expected {}, got {}", MANIFOLD_DIM, data.len());
        }
        Vector { data }
    }

    /// é›¶å‘é‡ (Origin)
    pub fn zeros() -> Self {
        Vector { data: vec![0.0; MANIFOLD_DIM] }
    }

    /// å‘é‡åŠ æ³•: $v + u$
    pub fn add(&self, other: &Self) -> Self {
        let new_data = self.data.iter()
            .zip(&other.data)
            .map(|(a, b)| a + b)
            .collect();
        Vector { data: new_data }
    }

    /// å‘é‡å‡æ³•: $v - u$
    pub fn sub(&self, other: &Self) -> Self {
        let new_data = self.data.iter()
            .zip(&other.data)
            .map(|(a, b)| a - b)
            .collect();
        Vector { data: new_data }
    }

    /// æ ‡é‡ä¹˜æ³•: $k \cdot v$
    pub fn scale(&self, scalar: Float) -> Self {
        let new_data = self.data.iter()
            .map(|a| a * scalar)
            .collect();
        Vector { data: new_data }
    }

    /// åŸå§‹æ•°æ®è®¿é—®
    pub fn as_slice(&self) -> &[Float] {
        &self.data
    }
}

impl Matrix {
    /// åˆ›å»ºæ–°çŸ©é˜µ
    pub fn new(rows: usize, cols: usize, data: Vec<Float>) -> Self {
        assert_eq!(data.len(), rows * cols, "Matrix data size does not match dimensions");
        Matrix { rows, cols, data }
    }

    /// å•ä½çŸ©é˜µ (Identity Matrix)
    /// $I \cdot v = v$
    pub fn identity() -> Self {
        let mut data = vec![0.0; MANIFOLD_DIM * MANIFOLD_DIM];
        for i in 0..MANIFOLD_DIM {
            data[i * MANIFOLD_DIM + i] = 1.0;
        }
        Matrix { 
            rows: MANIFOLD_DIM, 
            cols: MANIFOLD_DIM, 
            data 
        }
    }

    /// çŸ©é˜µä¹˜æ³• (Matrix Multiplication): $C = A \cdot B$
    /// æ³¨æ„ï¼šè¿™æ˜¯éäº¤æ¢æ“ä½œçš„æ ¸å¿ƒ (A*B != B*A)
    /// (Naive implementation O(N^3), production should use BLAS/Gemm)
    pub fn matmul(&self, other: &Self) -> Self {
        assert_eq!(self.cols, other.rows, "Matrix dimension mismatch for multiplication");
        let n = self.rows;
        let m = self.cols;
        let p = other.cols;
        
        let mut result = vec![0.0; n * p];
        
        // ç®€å•çš„ä¸‰é‡å¾ªç¯å®ç°
        for i in 0..n {
            for k in 0..m {
                let r = self.data[i * m + k];
                // ä¼˜åŒ–ï¼šè·³è¿‡ 0 å…ƒç´ 
                if r.abs() > 1e-9 {
                    for j in 0..p {
                        result[i * p + j] += r * other.data[k * p + j];
                    }
                }
            }
        }
        
        Matrix { rows: n, cols: p, data: result }
    }

    /// çŸ©é˜µ-å‘é‡ä¹˜æ³• (Matrix-Vector Product): $y = A \cdot x$
    pub fn matmul_vec(&self, vec: &Vector) -> Vector {
        assert_eq!(self.cols, vec.data.len(), "Matrix-Vector dimension mismatch");
        let mut result = vec![0.0; self.rows];
        
        for i in 0..self.rows {
            let mut sum = 0.0;
            for j in 0..self.cols {
                sum += self.data[i * self.cols + j] * vec.data[j];
            }
            result[i] = sum;
        }
        
        Vector { data: result }
    }

    /// çŸ©é˜µåŠ æ³• (Matrix Addition): $A + B$
    pub fn add(&self, other: &Self) -> Self {
        assert_eq!(self.data.len(), other.data.len(), "Matrix addition shape mismatch");
        let new_data = self.data.iter()
            .zip(&other.data)
            .map(|(a, b)| a + b)
            .collect();
        Matrix { rows: self.rows, cols: self.cols, data: new_data }
    }

    /// çŸ©é˜µç¼©æ”¾ (Scalar Multiplication): $k \cdot A$
    pub fn scale(&self, scalar: Float) -> Self {
        let new_data = self.data.iter()
            .map(|a| a * scalar)
            .collect();
        Matrix { rows: self.rows, cols: self.cols, data: new_data }
    }

    /// ğŸ›¡ï¸ [Safety Check]: Spectral Norm Calculation
    /// ç”¨äºéªŒè¯ Lipschitz è¿ç»­æ€§ã€‚ä¸ºäº†æ€§èƒ½ï¼Œè¿™é‡Œä½¿ç”¨ Frobenius Norm ä½œä¸ºä¸Šç•Œè¿‘ä¼¼ã€‚
    /// $\|A\|_F = \sqrt{\sum a_{ij}^2} \ge \|A\|_2$
    pub fn spectral_norm(&self) -> Float {
        self.data.iter()
            .map(|x| x * x)
            .sum::<Float>()
            .sqrt()
    }
}
