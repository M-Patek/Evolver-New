// COPYRIGHT (C) 2025 M-Patek. ALL RIGHTS RESERVED.

use super::affine::AffineTuple;
use super::algebra::{Vector, Matrix};
use serde::{Serialize, Deserialize};

/// ðŸ§  HTPNeuron: é€»è¾‘æµå½¢ä¸Šçš„åŸºæœ¬ç¥žç»å•å…ƒ
///
/// ä¸Žè¾“å‡ºæ ‡é‡æ¿€æ´»å€¼çš„ä¼ ç»Ÿç¥žç»å…ƒä¸åŒï¼ŒHTP ç¥žç»å…ƒç»´æŠ¤ç€ä¸€ä¸ªé«˜ç»´åæ ‡ (Vector)ã€‚
/// å®ƒä¸ä»…ä»…æ˜¯â€œæ¿€æ´»â€ï¼Œå®ƒæ˜¯â€œæ€è€ƒâ€çš„ä¸€ä¸ªå¿«ç…§ã€‚
///
/// çŠ¶æ€æ–¹ç¨‹: S_t = W * S_{t-1} + b
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct HTPNeuron {
    /// ðŸ“ Current Logic Coordinate (å½“å‰æ€ç»´åæ ‡)
    /// ä»£è¡¨è¯¥ç¥žç»å…ƒå½“å‰æŒæœ‰çš„é€»è¾‘çŠ¶æ€ S
    pub state: Vector,

    /// âš™ï¸ Intrinsic Logic Gate (å†…åœ¨é€»è¾‘é—¨ / æƒé‡)
    /// å®šä¹‰äº†è¯¥ç¥žç»å…ƒå¦‚ä½•å¤„ç†è¾“å…¥ä¿¡æ¯ï¼š(W, b)
    pub logic_gate: AffineTuple,
}

impl HTPNeuron {
    /// Genesis: åœ¨åŽŸç‚¹åˆ›å»ºä¸€ä¸ªç©ºç™½ç¥žç»å…ƒ
    /// åˆå§‹çŠ¶æ€ä¸º 0ï¼Œé€»è¾‘é—¨ä¸ºæ’ç­‰å˜æ¢ (Identity)
    pub fn new() -> Self {
        HTPNeuron {
            state: Vector::zeros(),
            logic_gate: AffineTuple::identity(),
        }
    }

    /// ä½¿ç”¨ç‰¹å®šçš„æƒé‡åˆå§‹åŒ–ç¥žç»å…ƒ
    pub fn with_weights(linear: Matrix, bias: Vector) -> Self {
        HTPNeuron {
            state: Vector::zeros(),
            logic_gate: AffineTuple::new(linear, bias),
        }
    }

    /// ðŸ”„ Time Evolution / Forward Pass (æ—¶é—´æ¼”åŒ–)
    ///
    /// ç‰©ç†å«ä¹‰: ç¥žç»å…ƒ "å¸æ”¶" è¾“å…¥çŠ¶æ€ï¼Œåº”ç”¨è‡ªå·±çš„é€»è¾‘è§„åˆ™ï¼ŒæŽ¨å¯¼å‡ºæ–°çš„çŠ¶æ€ã€‚
    /// å…¬å¼: S_new = W * S_input + b
    pub fn absorb(&mut self, input: &Vector) -> Vector {
        // 1. Apply Linear Logic (W * x)
        // è¿™ä¸€æ­¥ä»£è¡¨ "æŽ¨ç†" (Deduction)
        let linear_part = self.logic_gate.linear.matmul_vec(input);

        // 2. Apply Bias/Correction (+ b)
        // è¿™ä¸€æ­¥ä»£è¡¨ "ä¿®æ­£" (Adjustment)
        let new_state = linear_part.add(&self.logic_gate.translation);

        // 3. Update Internal Memory
        self.state = new_state.clone();

        new_state
    }

    /// ðŸ§¬ Algebraic One-Shot Learning (ä»£æ•°é€†è§£ / çž¬é—´å­¦ä¹ )
    ///
    /// è¿™æ˜¯ä¸€ä¸ª "Solver" çš„å¾®è§‚å®žçŽ°ã€‚
    /// åœºæ™¯: å¦‚æžœæˆ‘ä»¬çŸ¥é“å¯¹äºŽè¾“å…¥ Inputï¼Œæ­£ç¡®çš„è¾“å‡ºå¿…é¡»æ˜¯ Targetã€‚
    /// å‡è®¾ W å›ºå®šï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸€æ­¥ä¹‹å†…æ±‚è§£å‡ºéœ€è¦çš„åå·® bã€‚
    ///
    /// å…¬å¼: b = Target - W * Input
    pub fn force_learn_bias(&mut self, input: &Vector, target: &Vector) {
        // è®¡ç®— W * Input
        let predicted_linear = self.logic_gate.linear.matmul_vec(input);
        
        // æ±‚è§£ b = Target - Prediction
        let new_bias = target.sub(&predicted_linear);
        
        // çž¬é—´æ›´æ–°æƒé‡ï¼Œæ— éœ€è¿­ä»£
        self.logic_gate.translation = new_bias;
    }
    
    /// ðŸ” Manifold Integrity Check (æµå½¢å®Œæ•´æ€§æ£€æŸ¥)
    /// é˜²æ­¢ NaN (Not a Number) æˆ– Inf (æ— ç©·å¤§) æ±¡æŸ“ç½‘ç»œã€‚
    /// é€™æ˜¯ "Zero Hallucination" çš„ç‰©ç†åŸºç¡€ä¹‹ä¸€ã€‚
    pub fn verify_integrity(&self) -> Result<(), String> {
        for val in self.state.as_slice() {
            if !val.is_finite() {
                return Err("ðŸ”¥ Neuron Meltdown: State contains NaN or Infinity. Logic manifold collapsed.".to_string());
            }
        }
        Ok(())
    }
}
